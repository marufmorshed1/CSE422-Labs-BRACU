# -*- coding: utf-8 -*-
"""3_20101239_MdRaihanulIslamBhuiyan

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LEhGTmOowQQvBME1FYSGsH926XftNZ7w
"""

import pandas as pd
import numpy as np
import sklearn

sample=pd.read_csv('/content/sample_data/wine.csv')
sample.shape



!python -m pip show scikit-learn

sample

sample.isnull().sum()

sample.info()

from sklearn.preprocessing import LabelEncoder


#creating object
enc=LabelEncoder()

#Encoding quality column

sample['quality']=enc.fit_transform(sample['quality'])

#comparing two column

print( sample[['quality']].head(100))

sample_copy=sample.copy()

"""Minimax Formula"""

for column in sample_copy.columns:
  sample_copy[column] = (sample_copy[column] - sample_copy[column].min()) / (sample_copy[column].max() - sample_copy[column].min())    

sample_copy

sample.columns
X= sample_copy[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',
       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',
       'pH', 'sulphates', 'alcohol']]
y= sample_copy[['quality']]

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test=train_test_split(X,y, random_state=1,test_size=0.2)

X_train.shape

X_test.shape

print("per-feature minimum after scaling:\n {}".format(
    X_train.min(axis=0)))
print("per-feature maximum after scaling:\n {}".format(
    X_train.max(axis=0)))

from sklearn.svm import SVC
svc = SVC(kernel="linear")
svc.fit(X_train, y_train)

print("Training accuracy of the model is {:.2f}".format(svc.score(X_train, y_train)))
print("Testing accuracy of the model is {:.2f}".format(svc.score(X_test, y_test)))
svc_before=svc.score(X_test, y_test)

from sklearn.neural_network import MLPClassifier
nnc=MLPClassifier(hidden_layer_sizes=(1000), activation="relu", max_iter=10000000)

nnc.fit(X_train, y_train)

print("The Training accuracy of the model is {:.2f}".format(nnc.score(X_train, y_train)))
print("The Testing accuracy of the model is {:.2f}".format(nnc.score(X_test, y_test)))
nnc_before=nnc.score(X_test, y_test)

predictions = nnc.predict(X_test)
print(predictions)

print(y_test)

from sklearn.ensemble import RandomForestClassifier
clf=RandomForestClassifier(n_estimators=200)
clf.fit(X_train,y_train)
predictions = clf.predict(X_test)

print("The Training accuracy of the model is {:.2f}".format(clf.score(X_train, y_train)))
print("The Testing accuracy of the model is {:.2f}".format(clf.score(X_test, y_test)))
clf_before=clf.score(X_test, y_test)

predictions = clf.predict(X_test)
print(predictions)

print(y_test)

sample_copy.shape

"""PCA"""

from sklearn.decomposition import PCA
pca=PCA(n_components=6)

principal_components= pca.fit_transform(X_train,y_train)
print(principal_components)

pca.explained_variance_ratio_

sum(pca.explained_variance_ratio_)

principal_df = pd.DataFrame(data=principal_components, columns=["pc1",'pc2','pc3',"pc4",'pc5','pc6',])
#principal_df.head()
main_df=pd.concat([principal_df, sample_copy[["quality"]]], axis=1)

main_df.head()

main_df.isnull().sum()

main_df.shape

main_df = main_df[main_df['pc1'].notnull()]

main_df = main_df[main_df['pc2'].notnull()]

main_df = main_df[main_df['pc3'].notnull()]

main_df = main_df[main_df['pc4'].notnull()]

main_df = main_df[main_df['pc5'].notnull()]

main_df = main_df[main_df['pc6'].notnull()]

main_df.shape

"""Apply Support Vector Machine, Neural Network (MLPClassifier) and Random Forest again on the reduced dataset."""

X= main_df[["pc1",'pc2','pc3',"pc4",'pc5','pc6']]
y= main_df[['quality']]

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test=train_test_split(X,y, random_state=1,test_size=0.2)

from sklearn.svm import SVC
svc = SVC(kernel="linear")
svc.fit(X_train, y_train)

print("Training accuracy of the model is {:.2f}".format(svc.score(X_train, y_train)))
print("Testing accuracy of the model is {:.2f}".format(svc.score(X_test, y_test)))
svc_after=svc.score(X_test, y_test)

from sklearn.neural_network import MLPClassifier
nnc=MLPClassifier(hidden_layer_sizes=(1000), activation="relu", max_iter=10000000)

nnc.fit(X_train, y_train)

print("The Training accuracy of the model is {:.2f}".format(nnc.score(X_train, y_train)))
print("The Testing accuracy of the model is {:.2f}".format(nnc.score(X_test, y_test)))
nnc_after=nnc.score(X_test, y_test)

from sklearn.ensemble import RandomForestClassifier
clf=RandomForestClassifier(n_estimators=200)
clf.fit(X_train,y_train)
predictions = clf.predict(X_test)

print("The Training accuracy of the model is {:.2f}".format(clf.score(X_train, y_train)))
print("The Testing accuracy of the model is {:.2f}".format(clf.score(X_test, y_test)))
clf_after=clf.score(X_test, y_test)

x=[svc_before,nnc_before,clf_before,svc_after,nnc_after,clf_after]

fig = plt.figure()
ax = fig.add_axes([0,0,1,1])
langs = ['svc_before','nnc_before','clf_before','svc_after','nnc_after','clf_after']
ax.bar(langs,x)
plt.show()